-------------------------------------------------------------------------------
Using 1000009 tokens for training (100% of 1000009)
-------------------------------------------------------------------------------
Most frequent n-grams for n=1,2,3
(('the',), 62469)             	(('of', 'the'), 6657)         	(('the', 'united', 'states'), 538)
(('to',), 28616)              	(('in', 'the'), 6644)         	(('president', 'barack', 'obama'), 323)
(('of',), 24045)              	(('to', 'the'), 2720)         	(('one', 'of', 'the'), 320)   
(('in',), 23200)              	(('for', 'the'), 2332)        	(('said', 'in', 'a'), 265)    
(('and',), 22750)             	(('on', 'the'), 2246)         	(('the', 'end', 'of'), 264)   
(('a',), 22421)               	(('at', 'the'), 2165)         	(('in', 'the', 'first'), 225) 
(('on',), 11120)              	(('in', 'a'), 1944)           	(('the', 'white', 'house'), 224)
(('for',), 9716)              	(('and', 'the'), 1641)        	(('out', 'of', 'the'), 208)   
(('that',), 9349)             	(('with', 'the'), 1390)       	(('as', 'well', 'as'), 207)   
(('he',), 7980)               	(('to', 'be'), 1378)          	(('a', 'lot', 'of'), 204)     
Saved plot at basic.pdf
-------------------------------------------------------------------------------
Using vocab size 69148 (excluding UNK) (original 69148)
